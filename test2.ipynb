{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_path = \"../Bio_Project/SRR184065/reads_datasets/SRR1804065_1.filtr.fq\"\n",
    "dataset_path = \"../all_118309_1.fq\"\n",
    "\n",
    "#clusters_path =  \"../Bio_Project/1_upSingleOutput/1_up+RC.fasta.a16.t20.txt\"\n",
    "#clusters_path =  \"../Bio_Project/results/all_1/all_118309_1+RC.fasta.a16.t20.txt\"\n",
    "#clusters_path =  \"../Bio_Project/results/all_2/all_118309_2+RC.fasta.a16.t20.txt\"\n",
    "clusters_path =  \"../all_118309_1+RC.fasta.a16.t20.txt\"\n",
    "#clusters_path =  \"../Bio_Project/results/output1_up/1_up+RC.fasta.a16.t20.txt\"\n",
    "\n",
    "# classifier_path = \"../Bio_Project/SmallDataset/classifiers_results/strex_centrifuge_118309.res\"\n",
    "classifier_path = \"../strex_kraken1_118309.res\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset function \n",
    "- If dataset is in fasta format then dataset_format parameter equals TRUE.\n",
    "- If dataset is in fastq format then dataset_format equals FALSE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, datset_format : bool):\n",
    "\n",
    "    dataset = open(path, \"r\")\n",
    "    dataset_lines = []\n",
    "\n",
    "    if (datset_format):\n",
    "        divisor = 2\n",
    "    else:\n",
    "        divisor = 4\n",
    "\n",
    "    index = 0\n",
    "    for line in dataset:\n",
    "        if (index%divisor==0):\n",
    "            read_id = line.split()[0]\n",
    "            dataset_lines.append(read_id[1: len(read_id)-2])\n",
    "        index = index + 1\n",
    "\n",
    "    dataset.close()\n",
    "\n",
    "    return dataset_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load clusters result function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clusters_result(path):\n",
    "\n",
    "    clusters = open(path, \"r\")\n",
    "    clusters_list = []\n",
    "\n",
    "    for group in clusters:\n",
    "        clusters_list.append(int(group))\n",
    "\n",
    "    clusters.close()\n",
    "\n",
    "    return clusters_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load classifier result function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classifier_result(path):\n",
    "\n",
    "    classification = open(path, 'r')\n",
    "    classifier_results = []\n",
    "\n",
    "    for line in classification:\n",
    "        col = []\n",
    "        for j in range(0, len(line.split())):\n",
    "            col.append(line.split()[j])\n",
    "        #read_id = line.split()[0]\n",
    "        #class_id = line.split()[1]\n",
    "        #col.append(read_id)\n",
    "        #col.append(class_id)\n",
    "        classifier_results.append(col)\n",
    "\n",
    "    classification.close()\n",
    "\n",
    "    return classifier_results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get inverted index function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inverted_index(clusters, read_ids):\n",
    "\n",
    "    inverted_index = []\n",
    "    num_clusters = max(clusters) + 1\n",
    "    num_reads = len(read_ids)\n",
    "\n",
    "    for i in range(0, num_clusters):\n",
    "        col = []\n",
    "        for j in range(0, num_reads):\n",
    "            if (clusters[j] == i):\n",
    "                col.append(read_ids[j])\n",
    "        inverted_index.append(col)\n",
    "\n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find labels function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_labels(read_ids, classification_output):\n",
    "\n",
    "    complete_classifier_result = []\n",
    "    found : bool = False\n",
    "    count = 0\n",
    "    for i in range(0, len(read_ids)):\n",
    "        for j in range(0, len(classification_output)):\n",
    "            col = []\n",
    "            if (read_ids[i] == classification_output[j][0]):\n",
    "                complete_classifier_result.append(classification_output[j])\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            count = count +1\n",
    "            complete_classifier_result.append(read_ids[i], '0')\n",
    "\n",
    "    print(\"count: \", count)\n",
    "    print(\"length classification output: \", len(classification_output))\n",
    "    print(\"length complete classification output: \", len(complete_classifier_result))\n",
    "\n",
    "    return complete_classifier_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find labels frequency function\n",
    "This function takes in input a cluster (group of reads, each read is identified by its read_id) and the classification of reads performed by a classifier\n",
    "and return a dictionary composed by key-value pairs where the key is a label and value equals to the frequency of such label in the cluster provided in input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_labels_frequency(cluster, classification_output):\n",
    "\n",
    "    label_dict = {}\n",
    "\n",
    "    classification_output = insertion_sort(classification_output)\n",
    "\n",
    "    for read in cluster:\n",
    "\n",
    "        position = binary_search_list(classification_output, read)\n",
    "\n",
    "        if (position == -1):\n",
    "            print(\"Something went wrong :-(\")\n",
    "            break\n",
    "\n",
    "        read_label = classification_output[position][1]\n",
    "        # print(read_label)\n",
    "\n",
    "        found : bool = False\n",
    "\n",
    "        labels = list(label_dict)\n",
    "\n",
    "        for label in list(label_dict):\n",
    "            if (label == read_label):\n",
    "                label_dict[read_label] = label_dict[read_label] + 1\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            label_dict[read_label] = 1\n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find lonely reads function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lonely_reads(clusters):\n",
    "\n",
    "    lonely_reads = []\n",
    "\n",
    "    for i in range(0, len(clusters)):\n",
    "        if (len(clusters[i]) == 1):\n",
    "            lonely_reads.append(clusters[i][0])\n",
    "\n",
    "    return lonely_reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find non classified reads function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_classified_reads(read_ids, classification_output):\n",
    "\n",
    "    non_classified_reads = []\n",
    "\n",
    "    if (len(read_ids) > len(classification_output)):\n",
    "        print(\"le read non classificate non sono presenti nel file di output, DA IMPLEMENTARE\")\n",
    "    elif (len(read_ids) == len(classification_output)):\n",
    "        ###print(\"le read non classificate hanno label = 0\")\n",
    "        for i in range(0, len(classification_output)):\n",
    "            if (classification_output[i][1] == '0'):\n",
    "                non_classified_reads.append(classification_output[i][0])\n",
    "    else:\n",
    "        print(\"Error in input files!\")\n",
    "\n",
    "    return non_classified_reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic operation functions\n",
    "- intersection\n",
    "- binary search\n",
    "- insertion sort\n",
    "- diff\n",
    "- binary search list\n",
    "- insertion sort list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3\n",
    "\n",
    "\n",
    "# Iterative Binary Search Function\n",
    "# It returns index of x in given array arr if present,\n",
    "# else returns -1\n",
    "def binary_search(arr, x):\n",
    "    low = 0\n",
    "    high = len(arr) - 1\n",
    "    mid = 0\n",
    "    while low <= high:\n",
    "        mid = (high + low) // 2\n",
    "        # If x is greater, ignore left half\n",
    "        if arr[mid] < x:\n",
    "            low = mid + 1\n",
    "        # If x is smaller, ignore right half\n",
    "        elif arr[mid] > x:\n",
    "            high = mid - 1\n",
    "        # means x is present at mid\n",
    "        else:\n",
    "            return mid\n",
    "    # If we reach here, then the element was not present\n",
    "    return -1\n",
    "\n",
    "\n",
    "def insertion_sort(arr):\n",
    "        \n",
    "    for i in range(len(arr)):\n",
    "        cursor = arr[i]\n",
    "        pos = i  \n",
    "        while pos > 0 and arr[pos - 1] > cursor:\n",
    "            # Swap the number down the list\n",
    "            arr[pos] = arr[pos - 1]\n",
    "            pos = pos - 1\n",
    "        # Break and do the final swap\n",
    "        arr[pos] = cursor\n",
    "    return arr\n",
    "\n",
    "# Python code t get difference of two lists\n",
    "# Not using set()\n",
    "def Diff(li1, li2):\n",
    "    li_dif = [i for i in li1 + li2 if i not in li1 or i not in li2]\n",
    "    return li_dif\n",
    "\n",
    "# Iterative Binary Search Function\n",
    "# It returns index of x in given array arr if present,\n",
    "# else returns -1\n",
    "def binary_search_list(arr, x):\n",
    "    low = 0\n",
    "    high = len(arr) - 1\n",
    "    mid = 0\n",
    "    while low <= high:\n",
    "        mid = (high + low) // 2\n",
    "        #print(arr[mid][0])\n",
    "        # If x is greater, ignore left half\n",
    "        if arr[mid][0] < x:\n",
    "            low = mid + 1\n",
    "        # If x is smaller, ignore right half\n",
    "        elif arr[mid][0] > x:\n",
    "            high = mid - 1\n",
    "        # means x is present at mid\n",
    "        else:\n",
    "            return mid\n",
    "    # If we reach here, then the element was not present\n",
    "    return -1\n",
    "\n",
    "\n",
    "\n",
    "def insertion_sort_list(arr):\n",
    "        \n",
    "    for i in range(len(arr)):\n",
    "        cursor = arr[i][0]\n",
    "        pos = i\n",
    "        while pos > 0 and arr[pos - 1][0] > cursor:\n",
    "            # Swap the number down the list\n",
    "            arr[pos][0] = arr[pos - 1][0]\n",
    "            pos = pos - 1\n",
    "        # Break and do the final swap\n",
    "        arr[pos][0] = cursor\n",
    "\n",
    "    return arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find labels (improved) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_labels_improved(read_ids, classification_output):\n",
    "\n",
    "    complete_classifier_result = []\n",
    "    found : bool = False\n",
    "    count = 0\n",
    "\n",
    "    classification_output = insertion_sort(classification_output)\n",
    "\n",
    "    print(\"classification_output sorted\")\n",
    "\n",
    "    for i in range(0, len(read_ids)):\n",
    "        position = binary_search_list(classification_output, str(read_ids[i]))\n",
    "        if (position == -1):\n",
    "            count = count + 1\n",
    "            complete_classifier_result.append([read_ids[i], '0'])\n",
    "        else:\n",
    "            complete_classifier_result.append(classification_output[position])\n",
    "\n",
    "    print(\"count: \", count)\n",
    "    print(\"length classification output: \", len(classification_output))\n",
    "    print(\"length complete classification output: \", len(complete_classifier_result))\n",
    "\n",
    "    return complete_classifier_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reassignment function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reassignment(inverted_index, max_labels):\n",
    "\n",
    "    reassigned_classification = []\n",
    "\n",
    "    for i in range(0, len(inverted_index)):\n",
    "        for j in range(0, len(inverted_index[i])):\n",
    "            reassigned_classification.append([inverted_index[i][j], max_labels[i]])\n",
    "\n",
    "    return reassigned_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_lines = load_dataset(dataset_path, False)\n",
    "clusters_list = load_clusters_result(clusters_path)\n",
    "classifier_results = load_classifier_result(classifier_path)\n",
    "\n",
    "###print (\"Lenght of dataset_lines: \", len(dataset_lines))\n",
    "###print (\"Length of classifier_results: \", len(classifier_results))\n",
    "\n",
    "if (len(dataset_lines) == len(clusters_list)):\n",
    "    num_reads = len(dataset_lines)\n",
    "    #print(\"ok\")\n",
    "else:\n",
    "    ###print (\"Error in input files!\")\n",
    "    exit()\n",
    "\n",
    "    # we add 1 to the max found value because the indexes of clusters start from 0 up to the max value.\n",
    "num_clusters = max(clusters_list) + 1\n",
    "\n",
    "###print(\"number of clusters: \", num_clusters)\n",
    "###print(\"number of reads: \", num_reads)\n",
    "\n",
    "#print(classifier_results)\n",
    "\n",
    "# INVERTED INDEX\n",
    "inverted_index = get_inverted_index(clusters_list, dataset_lines)\n",
    "\n",
    "i = 0\n",
    "max_label_per_cluster_list = []\n",
    "max_label_list = []\n",
    "for cluster in inverted_index:\n",
    "    label_dict = find_labels_frequency(cluster, classifier_results)\n",
    "    max_label = \"\"\n",
    "    max_count = 0\n",
    "    for label, count in label_dict.items():\n",
    "        #print(label, count)\n",
    "        if (count > max_count):\n",
    "            max_count = count\n",
    "            max_label = label\n",
    "    #print(\"CLUSTER: \", i, \" MAX_LABEL: \", max_label, \"MAX COUNT: \", max_count, \"CLUSTER LENGTH: \", len(cluster))\n",
    "    max_label_list.append(max_label)\n",
    "    max_label_per_cluster_list.append([max_label, max_count, len(cluster)])\n",
    "    i = i + 1\n",
    "\n",
    "###print(\"Max_label_per_cluster length: \", len(max_label_per_cluster_list))\n",
    "###print(\"Max_label_per_cluster: [max_label, max_count, len(cluster)]\")\n",
    "#print(max_label_per_cluster_list)\n",
    "\n",
    "non_cl_rds = 0\n",
    "for triplet in max_label_per_cluster_list:\n",
    "    #print(triplet)\n",
    "    if triplet[0] == '0':\n",
    "        #print(triplet)\n",
    "        non_cl_rds = non_cl_rds + triplet[2]\n",
    "\n",
    "###print(\"number of non classidied reads with LiME_binning clusters: \", non_cl_rds)\n",
    "\n",
    "#################################################################################################\n",
    "\n",
    "# REASSIGNMENT BASED ON MAJOR VOTE RULE\n",
    "# Take in input the inverted index, that is a list of [cluster_index, [set of reads]] pairs for cluster_index that goes from 0 up to num_clusters.\n",
    "# Take in input the value max_label for each cluster, so we will have a list of num_cluster + 1 values: [max_label_cl_0, max_label_cl_1, ..., max_label_cl_nume_cluster]\n",
    "# Return in output a list [read_id, label], where label is assigned to read_id dependig on the max_label value of the cluster the read belong to.\n",
    "# LET'S SEE IF I AM ABLE TO DO THIS!!\n",
    "\n",
    "reassigned_classification = reassignment(inverted_index, max_label_list) \n",
    "\n",
    "for element in reassigned_classification:\n",
    "    ###print(element)\n",
    "    print(element[0], end=' ')\n",
    "    print(element[1])\n",
    "\n",
    "#################################################################################################\n",
    "# NON CLASSIFIED READS\n",
    "non_classified_reads = find_non_classified_reads(dataset_lines, classifier_results)\n",
    "###print(\"number of non classified_reads: \", len(non_classified_reads))\n",
    "#print(non_classified_reads)\n",
    "#print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
