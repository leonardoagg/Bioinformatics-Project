{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_path = \"../../Bio_Project/SmallDataset/reads_datasets/all_118309_1.fq\"\n",
    "#classifier_path = \"../../Bio_Project/SmallDataset/classifiers_results/strex_centrifuge_118309.res\"\n",
    "#classifier_path = \"../../Bio_Project/SmallDataset/classifiers_results/strex_kraken1_118309.res\"\n",
    "#classifier_path = \"../../Bio_Project/SmallDataset/classifiers_results/strex_kraken2_118309.res\"\n",
    "#clusters_path =  \"../../Bio_Project/results/paired/all_118309_1+RC.fasta.a16.t20.txt\"\n",
    "clusters_path =  \"../../Bio_Project/results/LiME_binning_all_250000_1/all_250000_1+RC.fasta.a16.t20.txt\"\n",
    "\n",
    "dataset_path = \"../../Bio_Project/SimDataset/reads_datasets/all_250000_1.fq\"\n",
    "#classifier_path = \"../../Bio_Project/SimDataset/classifiers_results/strex_centrifuge_250000.res\"\n",
    "classifier_path = \"../../Bio_Project/SimDataset/classifiers_results/strex_kraken1_250000.res\"\n",
    "#classifier_path = \"../../Bio_Project/SimDataset/classifiers_results/strex_kraken2_250000.res\"\n",
    "#classifier_path = \"../../Bio_Project/SimDataset/classifiers_results/strex_clark_genus_250000.res\"\n",
    "#classifier_path = \"../../Bio_Project/SimDataset/classifiers_results/strex_clark_species_250000.res\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset function \n",
    "- If dataset is in fasta format then dataset_format parameter equals TRUE.\n",
    "- If dataset is in fastq format then dataset_format equals FALSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, datset_format : bool):\n",
    "\n",
    "    dataset = open(path, \"r\")\n",
    "    dataset_lines = []\n",
    "\n",
    "    if (datset_format):\n",
    "        divisor = 2\n",
    "    else:\n",
    "        divisor = 4\n",
    "\n",
    "    index = 0\n",
    "    for line in dataset:\n",
    "        if (index%divisor==0):\n",
    "            read_id = line.split()[0]\n",
    "            dataset_lines.append(read_id[1: len(read_id)-2])\n",
    "        index = index + 1\n",
    "\n",
    "    dataset.close()\n",
    "\n",
    "    return dataset_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load classifier result function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classifier_result(path):\n",
    "\n",
    "    classification = open(path, 'r')\n",
    "    classifier_results = []\n",
    "\n",
    "    for line in classification:\n",
    "        col = []\n",
    "        for j in range(0, len(line.split())):\n",
    "            col.append(line.split()[j])\n",
    "        #read_id = line.split()[0]\n",
    "        #class_id = line.split()[1]\n",
    "        #col.append(read_id)\n",
    "        #col.append(class_id)\n",
    "        classifier_results.append(col)\n",
    "\n",
    "    classification.close()\n",
    "\n",
    "    return classifier_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clusters_result(path):\n",
    "\n",
    "    clusters = open(path, \"r\")\n",
    "    clusters_list = []\n",
    "\n",
    "    for group in clusters:\n",
    "        clusters_list.append(int(group))\n",
    "\n",
    "    clusters.close()\n",
    "\n",
    "    return clusters_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inverted_index(clusters, classified_reads):\n",
    "\n",
    "    num_clusters = -1\n",
    "    for i in range (0, len(clusters_list)):\n",
    "        if (clusters_list[i] >= num_clusters):\n",
    "            num_clusters = clusters_list[i]\n",
    "    \n",
    "    num_clusters = num_clusters + 1\n",
    "    num_reads = len(clusters)\n",
    "    inverted_index = []\n",
    "    \n",
    "    for i in range(0, num_clusters):\n",
    "        inverted_index.append([])\n",
    "   \n",
    "    for i in range(0, num_reads):\n",
    "        inverted_index[clusters[i]].append(classified_reads[i])\n",
    "\n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatches:  624560\n",
      "matches:  2500440\n",
      "ok\n",
      "3125000\n"
     ]
    }
   ],
   "source": [
    "dataset_lines = load_dataset(dataset_path, False)\n",
    "clusters_list = load_clusters_result(clusters_path)\n",
    "classifier_results = load_classifier_result(classifier_path)\n",
    "\n",
    "if (len(dataset_lines) != len(classifier_results)):\n",
    "    print(\"Different length!\")\n",
    "    \n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "all_read_label_list = []\n",
    "count_mis = 0\n",
    "count_match = 0\n",
    "while(i < len(dataset_lines) and j < len(classifier_results)):\n",
    "    \n",
    "    if (dataset_lines[i] == classifier_results[j][0]):\n",
    "        all_read_label_list.append(classifier_results[j])\n",
    "        count_match = count_match + 1\n",
    "        i = i + 1\n",
    "        j = j + 1\n",
    "    else:\n",
    "        count_mis = count_mis + 1\n",
    "        all_read_label_list.append([dataset_lines[i], '0'])\n",
    "        i = i + 1\n",
    "\n",
    "while (i != len(dataset_lines)):\n",
    "    all_read_label_list.append([dataset_lines[i], '0'])\n",
    "    i = i + 1\n",
    "    count_mis = count_mis + 1\n",
    "\n",
    "print(\"mismatches: \", count_mis)\n",
    "print(\"matches: \", count_match)\n",
    "\n",
    "if (count_match + count_mis == len(dataset_lines)):\n",
    "    print(\"ok\")\n",
    "\n",
    "print(len(all_read_label_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "735204\n"
     ]
    }
   ],
   "source": [
    "inverted_index = get_inverted_index(clusters_list, all_read_label_list)\n",
    "\n",
    "print(len(inverted_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['taxid_1042876.1', '76759']]\n",
      "[['taxid_1042876.516', '76759'], ['taxid_1042876.41020', '76759'], ['taxid_1042876.62341', '76759']]\n"
     ]
    }
   ],
   "source": [
    "print(inverted_index[0])\n",
    "print(inverted_index[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_search(cluster):\n",
    "    \n",
    "    label_dict= {}\n",
    "       \n",
    "    for element in cluster:\n",
    "        element_label = element[1]\n",
    "        if element_label in list(label_dict):\n",
    "            label_dict[element_label] = label_dict[element_label] + 1\n",
    "        else:\n",
    "            # if it does not exist, it's automatically created\n",
    "            label_dict[element_label] = 1\n",
    "        \n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict_cluster_500 = frequency_search(inverted_index[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "76759 3\n"
     ]
    }
   ],
   "source": [
    "for label, frequency in label_dict_cluster_500.items():\n",
    "    print(label, frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "735204\n"
     ]
    }
   ],
   "source": [
    "all_dict = []\n",
    "\n",
    "for i in range (0, len(inverted_index)):\n",
    "    label_dict_cluster = frequency_search(inverted_index[i])\n",
    "    all_dict.append(label_dict_cluster)\n",
    "    \n",
    "print(len(all_dict))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
